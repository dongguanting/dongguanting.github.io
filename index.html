<html>

<head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-EWB73JXBN5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-EWB73JXBN5');
</script>
	
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<meta name="description" content="Homepage of KABI">
	<link rel="stylesheet" href="./files/jemdoc.css" type="text/css">
	<title>Guanting Dong's Homepage|董冠霆的个人主页</title>
</head>


<body>

<div id="layout-content" style="margin-top:25px">

<table><tbody><tr>
    <td width="670">
        <div id="toptitle"><h1>Guanting Dong (董冠霆)&nbsp;</h1></div>
        <h3>Ph.D. Student</h3>  
        <p>
            Dept. of Artificial Intelligence <br>
            Renmin University of China (RUC) <br>
            Beijing, China, 100084. <br>
	    WeChat: dongguanting990611 <br>
            Email:  <a href="mailto:dongguanting@ruc.edu.cn">dongguanting@ruc.edu.cn</a> <br>
		
            <a href="https://github.com/dongguanting">[Github]</a>
            <a href="https://scholar.google.com/citations?user=amozZDkAAAAJ&hl=zh-CN&oi=ao">[Google Scholar]</a>
            <a href="https://www.semanticscholar.org/author/Guanting-Dong/51490462?sort=influence">[Semantic Scholar]</a> 
            <a href="https://dblp.org/pid/227/7667.html">[DBLP]</a> 
	    <a href="https://twitter.com/kakakbibibi">[Twitter]</a> 
            <a href="https://www.zhihu.com/people/kakakakabi/posts">[知乎]</a> 

        </p>
    </td>

    <td><img src="./files/photo.jpg" border="0" width="120"></td>
</tr></tbody></table>


<h2>About</h2>
    <p>I am a first-year Ph.D. student at the <a href="http://ai.ruc.edu.cn/">Gaoling School of Artificial Intelligence</a>, Renmin University of China, fortunate to be co-advised by <a href="http://playbigdata.ruc.edu.cn/dou/">Prof. Zhicheng Dou</a> and <a href="https://scholar.google.com/citations?user=tbxCHJgAAAAJ&hl=zh-CN">Prof. Jirong Wen</a>. Previously, I received M.Eng (2024) and B.Eng (2021) degrees in Information and Communication Engineering from Beijing University of Posts and Telecommunications(BUPT)</a>, advised by <a href="https://pris-nlp.github.io/en/author/weiran-xu/">Prof. Weiran Xu</a>.</p>
    
    <p> Currently, My research interests focus on 
    <ul>
    
	    <li>
	        Multi-Modal Retrieval Augmented Generation
	    </li>
	    <li>
	        Alignment for Large Language Models
	    </li>
        <li>
	        Large Language Models Reasoning
	    </li>
	  
     </ul>
	
    <p> My long-term goal is to explore an automated, scalable, and safe way that fosters exceptional intelligence to achieve AGI.


<h2>News</h2>
<ul>
    <li><strong>[2025-1]</strong> We release <a href='https://arxiv.org/pdf/2501.05366'>Search-o1</a >, leveraging agentic search mechanism to enhance o1-like large reasoning models.  </li>
    <li><strong>[2024-12]</strong> Honored to be a contributor to the Qwen2.5 <img src="./files/qwen_logo.webp" style="width: 1em;" />, a series of LLMs designed to meet diverse needs! </li>
    <li><strong>[2024-12]</strong> Our <a href='https://arxiv.org/abs/2410.09584'>FollowRAG</a > has been accepted by AAAI 2025 dedicated to developing a reliable instruction-following RAG system.</li>
    <li><strong>[2024-09]</strong> Glad to be a Ph.D. student at GSAI, Renmin University of China. </li>
    <li><strong>[2024-09]</strong> Two papers have been accepted by EMNLP 2024!</li>
    <li><strong>[2024-07]</strong> We release our technical report of Qwen2 <img src="./files/qwen_logo.webp" style="width: 1em;" />. a large-scale language model developed by Alibaba Group. </li>
    <li><strong>[2024-05]</strong> Four papers have been accepted by ACL 2024! Looking forward to seeing you in Bangkok! </li>
    <li><strong>[2024-02]</strong> One paper have been accepted by NAACL 2024! </li>
</ul>
    


<h2>Experiences</h2>
	<strong>Academia</strong>
	<ul>
    <li>[2024.9 - Now]    <img style="width: 1em;"src="./files/ruc.webp"> Ph.D. at Renmin University of China</li>
	<li>[2021.9 - 2024.6]<img style="width: 1em;"src="./files/bupt.webp"> M.S. at Beijing University of Posts and Telecommunications</li>
		<li style="margin-left: 20px;">[2018.7 - 2018.8] <img style="width: 1em;"src="./files/oxford.webp"> Summer Exchange Internship at University of Oxford, UK</li>
	<li>[2017.9 - 2021.6] <img style="width: 1em;"src="./files/bupt.webp"> B.S. at Beijing University of Posts and Telecommunications</li>
    
</ul>


 <strong>Industry</strong>
	<ul>
	<li>[2023.6 - 2024.8] <img style="width: 2.4em;"src="./files/alibaba.png"> Alibaba, Qwen Team, Research Intern on Alignment & Reasoning of Large Language Models</li>
	<li>[2022.9 - 2023.5] <img style="width: 2.4em;"src="./files/meituan.png"> Meituan, NLP Center, Research Intern on Knowledge Augmented Generation</li>
</ul>

	
	
<h2>Publications & Preprints</h2>

(* denotes equal contributions)<br>

<h3>As the Core Author.</h3>

	
<strong>-2025-</strong>

<ul><li><p>Search-o1: Agentic Search-Enhanced Large Reasoning Models<br />
	Xiaoxi Li, <strong>Guanting Dong</strong>, Jiajie Jin, Yuyao Zhang, Yujia Zhou, Yutao Zhu, Peitian Zhang, Zhicheng Dou<br />
    Arxiv.
  <a href='https://arxiv.org/pdf/2501.05366'>[paper]</a >
    <a href='https://search-o1.github.io/'>[homepage]</a >
	<a href='https://github.com/sunnynexus/Search-o1'>[code]</a >
	<a href='https://mp.weixin.qq.com/s/gqnGyMM_KYYwDbHyWkIIuw'>[blog]</a><br>
	
</li>
</ul>
	

<ul><li><p>Toward General Instruction-Following Alignment for Retrieval-Augmented Generation<br />
    <strong>Guanting Dong</strong>, Xiaoshuai Song, Yutao Zhu, Runqi Qiao, Zhicheng Dou, Ji-Rong Wen<br />
    AAAI 2025 <span style="color: #A40000;">(CCF-A)</span>.
    <a href='https://arxiv.org/abs/2410.09584'>[paper]</a >
    <a href='https://followrag.github.io/'>[homepage]</a >
	<a href='https://github.com/dongguanting/FollowRAG'>[code]</a >
    <a href='https://huggingface.co/datasets/dongguanting/VIF-RAG-QA-110K'>[dataset]</a>
	<a href='https://zhuanlan.zhihu.com/p/15652951301'>[blog]</a><br>
</li>
</ul>
	

<strong>-2024-</strong>
	

<ul><li><p>Progressive Multimodal Reasoning via Active Retrieval<br />
    <strong>Guanting Dong</strong>, Chenghao Zhang, Mengjie Deng, Yutao Zhu, Zhicheng Dou, Ji-Rong Wen<br />
    Arxiv.
    <a href='https://arxiv.org/pdf/2412.14835'>[paper]</a >
	<a href='https://zhuanlan.zhihu.com/p/15638015036'>[blog]</a><br>
	
</li>
</ul>

	

	
<ul><li><p>Understand What LLM Needs: Dual Preference Alignment for Retrieval-Augmented Generation<br />
    <strong>Guanting Dong</strong>, Yutao Zhu, Chenghao Zhang, Zechen Wang, Zhicheng Dou, Ji-Rong Wen<br />
    Arxiv.
    <a href='https://arxiv.org/pdf/2406.18676'>[paper]</a >
	<a href='https://github.com/dongguanting/DPA-RAG'>[code]</a >
    <a href='https://mp.weixin.qq.com/s/GddtwVZBWlGVpugVHTjUOQ'>[blog]</a><br>
</li>
</ul>



<ul><li><p>DotaMath: Decomposition of Thought with Code Assistance and Self-correction for Mathematical Reasoning<br />
    Chengpeng Li, <strong>Guanting Dong</strong>, Mingfeng Xue, Ru Peng, Xiang Wang, Dayiheng Liu<br />
    Arxiv.
    <a href='https://arxiv.org/pdf/2407.04078'>[paper]</a >
	<a href='https://github.com/ChengpengLi1003/DotaMath'>[code]</a >
	<a href='https://huggingface.co/datasets/dongguanting/DotamathQA'>[dataset]</a >
    <a href='https://mp.weixin.qq.com/s/pH-A9MuDCCDaeOseeogghQ'>[blog]</a><br>
</li>
</ul>



<ul><li><p>Self-play with Execution Feedback: Improving Instruction-following Capabilities of Large Language Models<br />
    <strong>Guanting Dong</strong>, Keming Lu, Chengpeng Li, Tingyu Xia, Bowen Yu, Chang Zhou, Jingren Zhou<br />
    Arxiv.
    <a href='https://arxiv.org/pdf/2406.13542'>[paper]</a >
	<a href='https://github.com/QwenLM/AutoIF'>[code]</a >
    <a href='https://zhuanlan.zhihu.com/p/707012952'>[blog]</a><br>
</li>
</ul>

	
<ul><li><p>How Abilities in Large Language Models are Affected by Supervised Fine-tuning Data Composition<br />
    <strong>Guanting Dong</strong>, Hongyi Yuan, Keming Lu, Chengpeng Li, Mingfeng Xue, Dayiheng Liu, Wei Wang, Zheng Yuan, Chang Zhou, Jingren Zhou<br />
    ACL 2024 <span style="color: #A40000;">(CCF-A)</span>.
    <a href='https://arxiv.org/pdf/2310.05492.pdf'>[paper]</a>
	<a href='https://mp.weixin.qq.com/s/3RIBzuVlK0qHbO_Q04s-cw'>[blog]</a><br>
</li>
</ul>
	



<ul><li><p>Noise-BERT: A Unified Perturbation-Robust Framework with Noise Alignment Pre-training for Noisy Slot Filling Task<br />
Jinxu Zhao, <strong>Guanting Dong∗</strong>, Yueyan Qiu, Tingfeng Hui, Xiaoshuai Song, Daichi Guo, Weiran Xu<br />
ICASSP 2024 <span style="color: #A40000;">(CCF-B)</span>. 
<a href='https://arxiv.org/pdf/2402.14494.pdf'>[paper]</a>
</li>
</ul>



	
<strong>-2023-</strong>

<ul><li><p>InstructERC: Reforming Emotion Recognition in Conversation with a Retrieval Multi-task LLMs Framework<br />
    Shanglin Lei,<strong>Guanting Dong*</strong>, Xiaoping Wang, Keheng Wang, Sirui Wang<br />
    Arxiv. 
    <a href='https://arxiv.org/pdf/2309.11911.pdf'>[paper]</a>
    <a href='https://github.com/LIN-SHANG/InstructERC'>[code]</a> 
	<a href='https://mp.weixin.qq.com/s/Jj4Cf4xDmykeEYTvzNoFYg'>[blog]</a><br>
</li>
</ul>

	
<ul><li><p>DemoNSF: A Multi-task Demonstration-based Generative Framework for Noisy Slot Filling Task<br />
<strong>Guanting Dong</strong>, Tingfeng Hui, Zhuoma GongQue, Jinxu Zhao, Daichi Guo, Gang Zhao, Keqing He, Weiran Xu<br />
Findings of EMNLP 2023 (Shot Paper). 
<a href='https://aclanthology.org/2023.findings-emnlp.705.pdf'>[paper]</a>
<a href='https://github.com/dongguanting/Demo-NSF'>[code]</a>
<a href='https://mp.weixin.qq.com/s/zkdUkybrTafPQR9wpVmi3w'>[blog]</a><br>
	
</li>
</ul>


<ul><li><p>Semantic Parsing by Large Language Models for Intricate Updating Strategies of Zero-Shot Dialogue State Tracking<br />
Yuxiang Wu, <strong>Guanting Dong*</strong>, Weiran Xu<br />
Findings of EMNLP 2023 (Short Paper). 
<a href='https://aclanthology.org/2023.findings-emnlp.741.pdf'>[paper]</a>
<a href='https://github.com/ToLightUpTheSky/ParsingDST'>[code]</a> <br>
</li>
</ul>

<ul><li><p>A Multi-Task Semantic Decomposition Framework with Task-specific Pre-training for Few-Shot NER<br />
<strong>Guanting Dong</strong>, Zechen Wang, Jinxu Zhao, Gang Zhao, Daichi Guo, Dayuan Fu, Tingfeng Hui, Chen Zeng, Keqing He, Xuefeng Li, Liwen Wang, Xinyue Cui, Weiran Xu<br />
CIKM 2023 (Oral) <span style="color: #A40000;">(CCF-B)</span>.
<a href='https://arxiv.org/pdf/2308.14533.pdf'>[paper]</a>
<a href='https://github.com/dongguanting/MSDP-Fewshot-NER'>[code]</a> <br>
</li>
</ul>


<ul><li><p>Bridging the KB-Text Gap: Leveraging Structured Knowledge-aware Pre-training for KBQA<br />
<strong>Guanting Dong</strong>, Rumei Li, Sirui Wang, Yupeng Zhang, Yunsen Xian, Weiran Xu<br />
CIKM 2023 (Short Paper). 
<a href='https://arxiv.org/pdf/2308.14436.pdf'>[paper]</a>
<a href='https://github.com/dongguanting/SKP-for-KBQA'>[code]</a> <br>
</li>
</ul>

<ul><li><p>Revisit Input Perturbation Problems for LLMs: A Unified Robustness Evaluation Framework for Noisy Slot Filling Task<br />
<strong>Guanting Dong</strong>,  Jinxu Zhao, Tingfeng Hui, Daichi Guo, Wenlong Wang, Boqi Feng, Yueyan Qiu, Zhuoma Gongque, Keqing He, Zechen Wang, Weiran Xu<br />
NLPCC 2023 (Oral) <span style="color: #A40000;">(CCF-C)</span>.
<a href='https://arxiv.org/pdf/2310.06504.pdf'>[paper]</a>
<a href='https://github.com/dongguanting/Noise-Slot-Filling-LLM'>[code]</a> <br>
</li>
</ul>


<ul><li><p>Generative Zero-Shot Prompt Learning for Cross-Domain Slot Filling with Inverse Prompting<br />
Xuefeng Li, Liwen Wang, <strong>Guanting Dong*</strong>, Keqing He, Jinzheng Zhao, Hao Lei, Jiachi Liu, Weiran Xu<br />
Findings of ACL 2023 (Short Paper). 
<a href='https://aclanthology.org/2023.findings-acl.52.pdf'>[paper]</a>
<a href='https://github.com/LiXuefeng2020ai/GZPL'>[code]</a> <br>
</li>
</ul>


<ul><li><p>A Prototypical Semantic Decoupling Method via Joint Contrastive Learning for Few-Shot Named Entity Recognition<br />
<strong>Guanting Dong</strong>, Zechen Wang, Liwen Wang, Daichi Guo, Dayuan Fu, Yuxiang Wu, Chen Zeng, Xuefeng Li, Tingfeng Hui, Keqing He, Xinyue Cui, Qixiang Gao, Weiran Xu<br />
ICASSP 2023 <span style="color: #A40000;">(CCF-B)</span>. 
<a href='https://ieeexplore.ieee.org/abstract/document/10095149'>[paper]</a>
</li>
</ul>

<ul><li><p>Revisit Out-Of-Vocabulary Problem For Slot Filling: A Unified Contrastive Framework With Multi-Level Data Augmentations<br />
Daichi Guo, <strong>Guanting Dong*</strong>, Dayuan Fu, Yuxiang Wu, Chen Zeng, Tingfeng Hui, Liwen Wang, Xuefeng Li, Zechen Wang, Keqing He, Xinyue Cui, Weiran Xu<br />
ICASSP 2023 <span style="color: #A40000;">(CCF-B)</span>. 
<a href='https://ieeexplore.ieee.org/abstract/document/10094766/'>[paper]</a>
</li>
</ul>

<strong>-2022-</strong>

<ul><li><p>Exploiting domain-slot related keywords description for Few-Shot Cross-Domain Dialogue State Tracking<br />
Gao Qixiang, <strong>Guanting Dong*</strong>, Yutao Mou, Liwen Wang, Chen Zeng, Daichi Guo, Mingyang Sun, Weiran Xu<br />
EMNLP 2022 (Oral) (Short Paper). 
<a href='https://aclanthology.org/2022.emnlp-main.157.pdf'>[paper]</a>
</li>
</ul>


<ul><li><p>Entity-level Interaction via Heterogeneous Graph for Multimodal Named Entity Recognition<br />
Gang Zhao, <strong>Guanting Dong</strong>, Yidong Shi, Haolong Yan, Weiran Xu, Si Li<br />
Findings of EMNLP 2022 (Short Paper). 
<a href='https://aclanthology.org/2022.findings-emnlp.473.pdf'>[paper]</a>
<a href='https://github.com/GangZhao98/GEI'>[code]</a> <br>
</li>
</ul>


<ul><li><p>PSSAT: A Perturbed Semantic Structure Awareness Transferring Method for Perturbation-Robust Slot Filling<br />
<strong>Guanting Dong</strong>, Daichi Guo, Liwen Wang, Xuefeng Li, Zechen Wang, Chen Zeng, Keqing He, Jinzheng Zhao, Hao Lei, Xinyue Cui, Yi Huang, Junlan Feng, Weiran Xu<br />
COLING 2022 (Short Paper). 
<a href='https://aclanthology.org/2022.coling-1.473.pdf'>[paper]</a>
</li>
</ul>


<hr>
	

<h3>As a Co-author.</h3>



<strong>-2025-</strong>
	
<ul><li><p>INSNER: A generative instruction-based prompting method for boosting performance in few-shot NER<br />
    Peiwen Zhao, Chong Feng, Peiguang Li, <strong>Guanting Dong</strong>, Sirui Wang<br />
    Information Processing & Management <span style="color: #A40000;">(SCI-Q1)</span>.
    <a href='https://www.sciencedirect.com/science/article/abs/pii/S0306457324003996'>[paper]</a >
</li>
</ul>

	

<ul><li><p>PreAct: Predicting Future in ReAct Enhances Agent's Planning Ability<br />
Dayuan Fu, Jianzhao Huang, Siyuan Lu, <strong>Guanting Dong</strong>, Yejie Wang, Keqing He, Weiran Xu<br />
    COLING 2025 (Short Paper). 
    <a href='https://arxiv.org/pdf/2402.11534.pdf'>[paper]</a>
    <a href='https://github.com/Fu-Dayuan/PreAct'>[code]</a> 
	<a href='https://mp.weixin.qq.com/s/1R_0Q57_vu9uGr_3j0Ozwg'>[blog]</a><br>
</li>
</ul>



<strong>-2024-</strong>
	


<ul><li><p><img src="./files/qwen_logo.webp" style="width: 1em;" /> Qwen2.5 Technical Report<br />
    <strong>Core Contributors</strong>: An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, Huan Lin, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jingren Zhou, Junyang Lin, Kai Dang, Keming Lu, Keqin Bao, Kexin Yang, Le Yu, Mei Li, Mingfeng Xue, Pei Zhang, Qin Zhu, Rui Men, Runji Lin, Tianhao Li, Tingyu Xia, Xingzhang Ren, Xuancheng Ren, Yang Fan, Yang Su, Yichang Zhang, Yu Wan, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, Zihan Qiu <br />
   <strong>Contributors</strong>: Biao Sun, Bin Luo, Bin Zhang, Binghai Wang, Chaojie Yang, Chang Si, Cheng Chen, Chengpeng Li, Chujie Zheng, Fan Hong, <strong>Guanting Dong</strong>, Guobin Zhao, Hangrui Hu, Hanyu Zhao, Hao Lin, Hao Xiang, Haoyan Huang, Humen Zhong, Jialin Wang, Jialong Tang, Jiandong Jiang, Jianqiang Wan, Jianxin Ma, Jianyuan Zeng, Jie Zhang, Jin Xu, Jinkai Wang, Jinzheng He, Jun Tang, Ke Yi, Keqin Chen, Langshi Chen, Le Jiang, Lei Zhang, Liang Chen, Man Yuan, Mingkun Yang, Minmin Sun, Na Ni, Nuo Chen, Peng Wang, Peng Zhu, Pengcheng Zhang, Pengfei Wang, Qiaoyu Tang, Qing Fu, Rong Zhang, Ru Peng, Ruize Gao, Shanghaoran Quan, Shen Huang, Shuai Bai, Shuang Luo, Sibo Song, Song Chen, Tao He, Ting He, Wei Ding, Wei Liao, Weijia Xu, Wenbin Ge, Wenbiao Yin, Wenyuan Yu, Xianyan Jia, Xianzhong Shi, Xiaodong Deng, Xiaoming Huang, Ximing Zhou, Xinyu Wang, Xipin Wei, Xuejing Liu, Yang Liu, Yang Zhang, Yibo Miao, Yidan Zhang, Yikai Zhu, Yinger Zhang, Yong Jiang, Yong Li, Yongan Yue, Yuanzhi Zhu, Yunfei Chu, Zekun Wang, Zhaohai Li, Zheren Fu, Zhi Li, Zhibo Yang, Zhifang Guo, Zhipeng Zhang, Zhiying Xu, Zile Qiao, Ziye Meng <br />
    Arxiv.
    <a href='https://arxiv.org/pdf/2412.15115'>[paper]</a >
	<a href='https://github.com/QwenLM/Qwen2.5'>[code]</a >
    <a href='https://huggingface.co/Qwen'>[model]</a >
    <a href='https://modelscope.cn/organization/qwen'>[modelscope]</a >
    <a href='https://qwenlm.github.io/blog/qwen2.5/'>[blog]</a><br>
</li>
</ul>

	

<ul><li><p><img src="./files/qwen_logo.webp" style="width: 1em;" /> Qwen2 Technical Report<br />
    An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, <strong>Guanting Dong</strong>, Haoran Wei, Huan Lin, Jialong Tang, Jialin Wang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Ma, Jin Xu, Jingren Zhou, Jinze Bai, Jinzheng He, Junyang Lin, Kai Dang, Keming Lu, Keqin Chen, Kexin Yang, Mei Li, Mingfeng Xue, Na Ni, Pei Zhang, Peng Wang, Ru Peng, Rui Men, Ruize Gao, Runji Lin, Shijie Wang, Shuai Bai, Sinan Tan, Tianhang Zhu, Tianhao Li, Tianyu Liu, Wenbin Ge, Xiaodong Deng, Xiaohuan Zhou, Xingzhang Ren, Xinyu Zhang, Xipin Wei, Xuancheng Ren, Yang Fan, Yang Yao, Yichang Zhang, Yu Wan, Yunfei Chu, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, Zhihao Fan<br />
    Arxiv.
    <a href='https://arxiv.org/pdf/2407.10671'>[paper]</a >
	<a href='https://github.com/QwenLM/Qwen2'>[code]</a >
    <a href='https://huggingface.co/Qwen'>[model]</a >
    <a href='https://qwenlm.github.io/blog/qwen2/'>[blog]</a><br>
</li>
</ul>

<ul><li><p>CORAL: Benchmarking Multi-turn Conversational Retrieval-Augmentation Generation<br />
   Yiruo Cheng, Kelong Mao, Ziliang Zhao,  <strong>Guanting Dong</strong>, Hongjin Qian, Yongkang Wu, Tetsuya Sakai, Ji-Rong Wen, Zhicheng Dou<br />
    Arxiv.
    <a href='https://arxiv.org/pdf/2410.23090'>[paper]</a >
	<a href='https://github.com/Ariya12138/CORAL'>[code]</a >
</li>
</ul>


	
	
<ul><li><p>Smaller Language Models Are Better Instruction Evolvers<br />
   Tingfeng Hui, Lulu Zhao,  <strong>Guanting Dong</strong>, Yaqi Zhang, Hua Zhou, Sen Su<br />
    Arxiv.
    <a href='https://arxiv.org/pdf/2412.11231'>[paper]</a >
	<a href='https://github.com/HypherX/Evolution-Analysis'>[code]</a >
	<a href='https://zhuanlan.zhihu.com/p/15668033358'>[blog]</a><br>
</li>
</ul>

	
<ul><li><p>How Do Your Code LLMs Perform? Empowering Code Instruction Tuning with High-Quality Data<br />
   Yejie Wang, Keqing He, Dayuan Fu, Zhuoma Gongque, Heyang Xu, Yanxu Chen, Zhexu Wang, Yujia Fu, <strong>Guanting Dong</strong>, Muxi Diao, Jingang Wang, Mengdi Zhang, Xunliang Cai, Weiran Xu<br />
    EMNLP 2024 <span style="color: #A40000;">(CCF-B)</span>.
    <a href='https://arxiv.org/pdf/2409.03810'>[paper]</a >
	<a href='https://github.com/banksy23/XCoder'>[code]</a >
    <a href='https://mp.weixin.qq.com/s/57gziduRY-H4E3-Da6NgWw'>[blog]</a><br>
</li>
</ul>


	
<ul><li><p>MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making<br />
   Dayuan Fu, Biqing Qi, Yihuai Gao, Che Jiang, <strong>Guanting Dong</strong>, Bowen Zhou<br />
    EMNLP 2024 <span style="color: #A40000;">(CCF-B)</span>.
    <a href='https://arxiv.org/pdf/2409.16686'>[paper]</a >
</li>
</ul>

	
<ul><li><p>We-Math: Does Your Large Multimodal Model Achieve Human-like Mathematical Reasoning?<br />
    Runqi Qiao, Qiuna Tan, <strong>Guanting Dong</strong>, Minhui Wu, Chong Sun, Xiaoshuai Song, Zhuoma GongQue, Shanglin Lei, Zhe Wei, Miaoxuan Zhang, Runfeng Qiao, Yifan Zhang, Xiao Zong, Yida Xu, Muxi Diao, Zhimin Bao, Chen Li, Honggang Zhang<br />
    Arxiv.
    <a href='https://arxiv.org/pdf/2407.01284'>[paper]</a >
	<a href='https://we-math.github.io/'>[homepage]</a >
	<a href='https://github.com/We-Math/We-Math'>[code]</a >
	<a href='https://huggingface.co/datasets/We-Math/We-Math'>[dataset]</a >
    <a href='https://mp.weixin.qq.com/s/uU1lZV0Ymj31cmZryhffyQ'>[blog]</a><br>
</li>
</ul>


<ul><li><p>CS-Bench: A Comprehensive Benchmark for Large Language Models towards Computer Science Mastery<br />
    Xiaoshuai Song, Muxi Diao, <strong>Guanting Dong</strong>, Zhengyang Wang, Yujia Fu, Runqi Qiao, Zhexu Wang, Dayuan Fu, Huangxuan Wu, Bin Liang, Weihao Zeng, Yejie Wang, Zhuoma GongQue, Jianing Yu, Qiuna Tan, Weiran Xu<br />
    Arxiv.
    <a href='https://arxiv.org/pdf/2406.08587'>[paper]</a >
	<a href='https://csbench.github.io/'>[homepage]</a >
	<a href='https://github.com/csbench/csbench'>[code]</a >
	<a href='https://huggingface.co/datasets/CS-Bench/CS-Bench'>[dataset]</a >
    <a href='https://mp.weixin.qq.com/s/9DDSbKJt3rYisJi95fJ46w'>[blog]</a><br>

</li>
</ul>

<ul><li><p>MuggleMath: Assessing the Impact of Query and Response Augmentation on Math Reasoning<br />
Chengpeng Li, Zheng Yuan, Hongyi Yuan, <strong>Guanting Dong</strong>, Keming Lu, Jiancan Wu, Chuanqi Tan, Xiang Wang, Chang Zhou<br />
    ACL 2024 <span style="color: #A40000;">(CCF-A)</span>. 
    <a href='https://arxiv.org/pdf/2310.05506.pdf'>[paper]</a>
	<a href='https://github.com/LHRLAB/ChatKBQA'>[code]</a>
	<a href='https://zhuanlan.zhihu.com/p/663463273'>[blog]</a><br>
</li>
</ul>
	
<ul><li><p>ChatKBQA: A Generate-then-Retrieve Framework for Knowledge Base Question Answering with Fine-tuned Large Language Models
<br />
Haoran Luo, Haihong E, Zichen Tang, Shiyao Peng, Yikai Guo, Wentai Zhang, Chenghao Ma, <strong>Guanting Dong</strong>, Meina Song, Wei Lin<br />
    Findings of ACL 2024. 
    <a href='https://arxiv.org/pdf/2310.08975'>[paper]</a>
	<a href='https://github.com/OFA-Sys/gsm8k-ScRel'>[code]</a>
	<a href='https://mp.weixin.qq.com/s/rBioXGaCefgOJnrkcSOs3A'>[blog]</a><br>
</li>
</ul>
	
<ul><li><p>DolphCoder: Echo-Locating Code Large Language Models with Diverse and Multi-Objective Instruction Tuning<br />
Yejie Wang, Keqing He, <strong>Guanting Dong</strong>, Pei Wang, Weihao Zeng, Muxi Diao, Yutao Mou, Mengdi Zhang, Jingang Wang, Xunliang Cai, Weiran Xu<br />
    ACL 2024 <span style="color: #A40000;">(CCF-A)</span>.
    <a href='https://arxiv.org/pdf/2402.09136.pdf'>[paper]</a>
</li>
</ul>



<ul><li><p>Clear Up Confusion: Advancing Cross-Domain Few-Shot Relation Extraction through Relation-Aware Prompt Learning<br />
Ge Bai, Chenji Lu, Daichi Guo, Shilong Li, Ying Liu, Zhang Zhang, <strong>Guanting Dong</strong>, Ruifang Liu, Sun Yong<br />
    NAACL 2024 (Short Paper).
    <a href='https://aclanthology.org/2024.naacl-short.6.pdf'>[paper]</a>
</li>
</ul>
	

<ul><li><p>Knowledge Editing on Black-box Large Language Models<br />
Xiaoshuai Song, Zhengyang Wang, Keqing He, <strong>Guanting Dong</strong>, Jinxu Zhao, Weiran Xu<br />
    Arxiv. 
    <a href='https://arxiv.org/pdf/2402.08631.pdf'>[paper]</a>
	<a href='https://github.com/songxiaoshuai/postEdit'>[code]</a> 
	<a href='https://mp.weixin.qq.com/s/KUIAugOzQzcbfPc4jlGeuQ'>[blog]</a><br>
</li>
</ul>


	
<strong>-2023-</strong>


<ul><li><p>Large Language Models Meet Open-World Intent Discovery and Recognition: An Evaluation of ChatGPT<br />
Xiaoshuai Song, Keqing He, Pei Wang,  <strong>Guanting Dong</strong>, Yutao Mou, Jingang Wang, Yunsen Xian, Xunliang Cai, Weiran Xu<br />
    EMNLP 2024 <span style="color: #A40000;">(CCF-B)</span>.
    <a href='https://aclanthology.org/2023.emnlp-main.636.pdf'>[paper]</a>
	<a href='https://github.com/songxiaoshuai/OOD-Evaluation'>[code]</a> 
</li>
</ul>
	

<ul><li><p>Pay Attention to Implicit Attribute Values: A Multi-modal Generative Framework for AVE Task<br />
Yupeng Zhang, Shensi Wang, Peiguang Li, <strong>Guanting Dong</strong>, Sirui Wang, Yunsen Xian, Zhoujun Li, Hongzhi Zhang<br />
    Findings of ACL 2023 (Short Paper). 
    <a href='https://aclanthology.org/2023.findings-acl.831/'>[paper]</a>
	<a href='https://github.com/G0vi/DEFLATE'>[code]</a> 
	<a href='https://mp.weixin.qq.com/s/KUIAugOzQzcbfPc4jlGeuQ'>[blog]</a><br>
</li>
</ul>

	
<ul><li><p>Scaling relationship on learning mathematical reasoning with large language models<br />
    Zheng Yuan, Hongyi Yuan, Chengpeng Li, <strong>Guanting Dong</strong>, Chuanqi Tan, Chang Zhou<br />
    Arxiv. 
    <a href='https://arxiv.org/pdf/2308.01825.pdf'>[paper]</a>
	<a href='https://github.com/OFA-Sys/gsm8k-ScRel'>[code]</a>
	<a href='https://zhuanlan.zhihu.com/p/648000801'>[blog]</a><br>
</li>
</ul>

<strong>-2022-</strong>
	
<ul><li><p>A Robust Contrastive Alignment Method for Multi-domain Text Classification<br />
    Xuefeng Li, Hao Lei, Liwen Wang, <strong>Guanting Dong</strong>, Jinzheng Zhao, Jiachi Liu, Weiran Xu, Chunyun Zhang<br />
    ICASSP 2022 <span style="color: #A40000;">(CCF-B)</span>. 
    <a href='https://ieeexplore.ieee.org/abstract/document/9747192'>[paper]</a>

</li>
</ul>




<h2>Honors & Awards</h2>
<ul>

    <!-- <li>
        <strong>China National Scholarship</strong>, 2023
    </li> -->

    <li>
        <strong>
            <a href="http://ai.ruc.edu.cn/newslist/notice/20240301100.html">1st Place in the PhD Entrance Exam (Preliminary) at the GSAI, Renmin University of China</a>
        </strong>, 2024
    </li>

    <li>
<strong>
<a href="https://jw.beijing.gov.cn/tzgg/202410/t20241010_3916096.html">Outstanding Graduates of Beijing(Top 1%)</a>
    </strong>, 2024
    </li>
	
    <li>
        <strong>
            <a href="https://mp.weixin.qq.com/s/FhWj5PFPdgBfzp2QI8F28Q">National Scholarship for Master Students(Top 1%)</a>
        </strong>, 2023
    </li>

    <li>
        <strong>Outstanding Graduate of Master Students(Top 5%), BUPT</strong>, 2023
    </li>
    <li>
        <strong>Excellent First-class Scholarship for Master Students, BUPT(Two times)</strong>, 2021, 2022
    </li>
    <li>
        <strong>
        <a href="http://seretod.org/Challenge.html">1st Award on track 2 of SereTOD Challenge, EMNLP 2022</a>
        </strong>, 2022
    </li>
    <li>
        <strong>Gold Award for College Music Festival Instrumental Performance, Beijing</strong>, 2021
    </li>
    <li>
        <strong>The Mathematical Contest in Modeling, Honorable Mention</strong>, 2021
    </li>

</ul>


<h2>Services</h2>
<li>
<strong>PC Reviewer for</strong>: ACL, EMNLP, NAACL, COLING<br />
</li>

<li>
<strong>Reviewer for</strong>: ICLR, WWW,  ACL, EMNLP, NAACL, COLING<br />
</li>
	
<div id="footer">
	<div id="footer-text"></div>
</div>
&copy 2023 Guanting Dong  <br>

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
</script>  
总访问量<span id="busuanzi_value_site_pv"></span>次 <br>
总访客数<span id="busuanzi_value_site_uv"></span>人次 <br>

<a href="https://clustrmaps.com/site/1blbh"  title="Visit tracker for kunkuang.github.io"><img src="//www.clustrmaps.com/map_v2.png?d=Z8dyJa5Yjz2Z_i_LEAbfY0-TbrPurcZYl5i6ii_5Xbw&cl=ffffff" /></a>
</body>

</html>

<html>

<head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-EWB73JXBN5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-EWB73JXBN5');
</script>
	
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<meta name="description" content="Homepage of KABI">
	<link rel="stylesheet" href="./files/jemdoc.css" type="text/css">
	<title>Guanting Dong's Homepage|董冠霆的个人主页</title>
</head>


<body>

<div id="layout-content" style="margin-top:25px">

<table><tbody><tr>
    <td width="670">
        <div id="toptitle"><h1>Guanting Dong (董冠霆)&nbsp;</h1></div>
        <h3>Ph.D. Student</h3>  
        <p>
            Dept. of Artificial Intelligence <br>
            Renmin University of China (RUC) <br>
            Beijing, China, 100084. <br>
	    WeChat: dongguanting990611 <br>
            Email:  <a href="mailto:dongguanting@bupt.edu.cn">dongguanting@126.com</a> <br>
		
            <a href="https://github.com/dongguanting">[Github]</a>
            <a href="https://scholar.google.com/citations?user=amozZDkAAAAJ&hl=zh-CN&oi=ao">[Google Scholar]</a>
            <a href="https://www.semanticscholar.org/author/Guanting-Dong/51490462?sort=influence">[Semantic Scholar]</a> 
            <a href="https://dblp.org/pid/227/7667.html">[DBLP]</a> 
	    <a href="https://twitter.com/kakakbibibi">[Twitter]</a> 
            <a href="https://www.zhihu.com/people/kakakakabi/posts">[知乎]</a> 

        </p>
    </td>

    <td><img src="./files/photo.jpg" border="0" width="120"></td>
</tr></tbody></table>


<h2>About</h2>
    <p>I am a first-year Ph.D. student at the <a href="http://ai.ruc.edu.cn/">Gaoling School of Artificial Intelligence</a>, Renmin University of China, fortunate to be co-advised by <a href="http://playbigdata.ruc.edu.cn/dou/">Prof. Zhicheng Dou</a> and <a href="https://scholar.google.com/citations?user=tbxCHJgAAAAJ&hl=zh-CN">Prof. Jirong Wen</a>. Previously, I received M.Eng (2024) and B.Eng (2021) degrees in Information and Communication Engineering from Beijing University of Posts and Telecommunications(BUPT)</a>, advised by <a href="https://pris-nlp.github.io/en/author/weiran-xu/">Prof. Weiran Xu</a>.</p>
    
    <p> Currently, My research interests focus on 
    <ul>
    
	    <li>
	        Information Extration and Retrieval
	    </li>
	    <li>
	        Alignment for Large Language Models
	    </li>
        <li>
	        Multi-modal Reasoning
	    </li>
	  
     </ul>
	    
<h2>News</h2>
<ul>
    <li><strong>[2024-07]</strong> We release our technical report of Qwen2 <img src="./files/qwen_logo.webp" style="width: 1em;" />. a large-scale language model developed by Alibaba Group. </li>
    <li><strong>[2024-05]</strong> Four papers have been accepted by ACL 2024! Looking forward to seeing you in Bangkok! </li>
    <li><strong>[2024-02]</strong> One paper have been accepted by NAACL 2024! </li>
    <li><strong>[2024-12]</strong> Two papers have been accepted by ICASSP 2024! </li>
    <li><strong>[2023-10]</strong> Three paper has been accepted at the EMNLP 2023! </li>
    <li><strong>[2023-08]</strong> Two papers have been accepted by CIKM 2023, Looking forward to seeing you in Birmingham, UK!</li>
</ul>
    


<h2>Experiences</h2>
	<strong>Academia</strong>
	<ul>
    <li>[2024.9 - Now]    <img style="width: 1em;"src="./files/ruc.webp"> Ph.D. at Renmin University of China</li>
	<li>[2021.9 - 2024.6]<img style="width: 1em;"src="./files/bupt.webp"> M.S. at Beijing University of Posts and Telecommunications</li>
	<li>[2017.9 - 2021.6] <img style="width: 1em;"src="./files/bupt.webp"> B.S. at Beijing University of Posts and Telecommunications</li>
    <li>[2018.7 - 2018.8] <img style="width: 1em;"src="./files/oxford.webp"> Summer Exchange Internship at University of Oxford, UK</li>
</ul>
	
 	<strong>Industry</strong>
	<ul>
	<li>[2023.6 - 2024.8] <img style="width: 2.4em;"src="./files/alibaba.png"> Alibaba, Qwen Team, Research Intern on Alignment & Reasoning of Large Language Models</li>
	<li>[2022.9 - 2023.5] <img style="width: 2.4em;"src="./files/meituan.png"> Meituan, NLP Center, Research Intern on Knowledge Augmented Generation</li>
</ul>

<h2>Featured Preprints</h2>
	
<strong>-2024-</strong>


<ul><li><p><img src="./files/qwen_logo.webp" style="width: 1em;" /> Qwen2 Technical Report<br />
    An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, <strong>Guanting Dong</strong>, Haoran Wei, Huan Lin, Jialong Tang, Jialin Wang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Ma, Jin Xu, Jingren Zhou, Jinze Bai, Jinzheng He, Junyang Lin, Kai Dang, Keming Lu, Keqin Chen, Kexin Yang, Mei Li, Mingfeng Xue, Na Ni, Pei Zhang, Peng Wang, Ru Peng, Rui Men, Ruize Gao, Runji Lin, Shijie Wang, Shuai Bai, Sinan Tan, Tianhang Zhu, Tianhao Li, Tianyu Liu, Wenbin Ge, Xiaodong Deng, Xiaohuan Zhou, Xingzhang Ren, Xinyu Zhang, Xipin Wei, Xuancheng Ren, Yang Fan, Yang Yao, Yichang Zhang, Yu Wan, Yunfei Chu, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, Zhihao Fan<br />
    Arxiv.
    <a href='https://arxiv.org/pdf/2407.10671'>[paper]</a >
	<a href='https://github.com/QwenLM/Qwen2'>[code]</a >
    <a href='https://huggingface.co/Qwen'>[model]</a >
    <a href='https://qwenlm.github.io/blog/qwen2/'>[blog]</a><br>
</li>
</ul>


<ul><li><p>Understand What LLM Needs: Dual Preference Alignment for Retrieval-Augmented Generation<br />
    <strong>Guanting Dong</strong>, Yutao Zhu, Chenghao Zhang, Zechen Wang, Zhicheng Dou, Ji-Rong Wen<br />
    Arxiv.
    <a href='https://arxiv.org/pdf/2406.18676'>[paper]</a >
	<a href='https://github.com/dongguanting/DPA-RAG'>[code]</a >
    <a href='https://mp.weixin.qq.com/s/GddtwVZBWlGVpugVHTjUOQ'>[blog]</a><br>
</li>
</ul>


<ul><li><p>We-Math: Does Your Large Multimodal Model Achieve Human-like Mathematical Reasoning?<br />
    Runqi Qiao, Qiuna Tan, <strong>Guanting Dong</strong>, Minhui Wu, Chong Sun, Xiaoshuai Song, Zhuoma GongQue, Shanglin Lei, Zhe Wei, Miaoxuan Zhang, Runfeng Qiao, Yifan Zhang, Xiao Zong, Yida Xu, Muxi Diao, Zhimin Bao, Chen Li, Honggang Zhang<br />
    Arxiv.
    <a href='https://arxiv.org/pdf/2407.01284'>[paper]</a >
	<a href='https://we-math.github.io/'>[website]</a >
	<a href='https://github.com/We-Math/We-Math'>[code]</a >
	<a href='https://huggingface.co/datasets/We-Math/We-Math'>[dataset]</a >
    <a href='https://mp.weixin.qq.com/s/uU1lZV0Ymj31cmZryhffyQ'>[blog]</a><br>
</li>
</ul>


<ul><li><p>CS-Bench: A Comprehensive Benchmark for Large Language Models towards Computer Science Mastery<br />
    Xiaoshuai Song, Muxi Diao, <strong>Guanting Dong</strong>, Zhengyang Wang, Yujia Fu, Runqi Qiao, Zhexu Wang, Dayuan Fu, Huangxuan Wu, Bin Liang, Weihao Zeng, Yejie Wang, Zhuoma GongQue, Jianing Yu, Qiuna Tan, Weiran Xu<br />
    Arxiv.
    <a href='https://arxiv.org/pdf/2406.08587'>[paper]</a >
	<a href='https://csbench.github.io/'>[website]</a >
	<a href='https://github.com/csbench/csbench'>[code]</a >
	<a href='https://huggingface.co/datasets/CS-Bench/CS-Bench'>[dataset]</a >
    <a href='https://mp.weixin.qq.com/s/9DDSbKJt3rYisJi95fJ46w'>[blog]</a><br>

</li>
</ul>

<ul><li><p>DotaMath: Decomposition of Thought with Code Assistance and Self-correction for Mathematical Reasoning<br />
    Chengpeng Li, <strong>Guanting Dong</strong>, Mingfeng Xue, Ru Peng, Xiang Wang, Dayiheng Liu<br />
    Arxiv.
    <a href='https://arxiv.org/pdf/2407.04078'>[paper]</a >
	<a href='https://github.com/ChengpengLi1003/DotaMath'>[code]</a >
    <a href='https://mp.weixin.qq.com/s/pH-A9MuDCCDaeOseeogghQ'>[blog]</a><br>
</li>
</ul>



<ul><li><p>Self-play with Execution Feedback: Improving Instruction-following Capabilities of Large Language Models<br />
    <strong>Guanting Dong</strong>, Keming Lu, Chengpeng Li, Tingyu Xia, Bowen Yu, Chang Zhou, Jingren Zhou<br />
    Arxiv.
    <a href='https://arxiv.org/pdf/2406.13542'>[paper]</a >
	<a href='https://github.com/QwenLM/AutoIF'>[code]</a >
    <a href='https://zhuanlan.zhihu.com/p/707012952'>[blog]</a><br>
</li>
</ul>


<ul><li><p>PreAct: Predicting Future in ReAct Enhances Agent's Planning Ability<br />
Dayuan Fu, Jianzhao Huang, Siyuan Lu, <strong>Guanting Dong</strong>, Yejie Wang, Keqing He, Weiran Xu<br />
    Arxiv. 
    <a href='https://arxiv.org/pdf/2402.11534.pdf'>[paper]</a>
    <a href='https://github.com/Fu-Dayuan/PreAct'>[code]</a> 
	<a href='https://mp.weixin.qq.com/s/1R_0Q57_vu9uGr_3j0Ozwg'>[blog]</a><br>
</li>
</ul>


<ul><li><p>Knowledge Editing on Black-box Large Language Models<br />
Xiaoshuai Song, Zhengyang Wang, Keqing He, <strong>Guanting Dong</strong>, Jinxu Zhao, Weiran Xu<br />
    Arxiv. 
    <a href='https://arxiv.org/pdf/2402.08631.pdf'>[paper]</a>
	<a href='https://github.com/songxiaoshuai/postEdit'>[code]</a> 
	<a href='https://mp.weixin.qq.com/s/KUIAugOzQzcbfPc4jlGeuQ'>[blog]</a><br>
</li>
</ul>

<strong>-2023-</strong>
	
<ul><li><p>Scaling relationship on learning mathematical reasoning with large language models<br />
    Zheng Yuan, Hongyi Yuan, Chengpeng Li, <strong>Guanting Dong</strong>, Chuanqi Tan, Chang Zhou<br />
    Arxiv. 
    <a href='https://arxiv.org/pdf/2308.01825.pdf'>[paper]</a>
	<a href='https://github.com/OFA-Sys/gsm8k-ScRel'>[code]</a>
	<a href='https://zhuanlan.zhihu.com/p/648000801'>[blog]</a><br>
</li>
</ul>
	

</ul>	

<ul><li><p>InstructERC: Reforming Emotion Recognition in Conversation with a Retrieval Multi-task LLMs Framework<br />
    Shanglin Lei,<strong>Guanting Dong*</strong>, Xiaoping Wang, Keheng Wang, Sirui Wang<br />
    Arxiv. 
    <a href='https://arxiv.org/pdf/2309.11911.pdf'>[paper]</a>
    <a href='https://github.com/LIN-SHANG/InstructERC'>[code]</a> 
	<a href='https://mp.weixin.qq.com/s/Jj4Cf4xDmykeEYTvzNoFYg'>[blog]</a><br>
</li>
</ul>
	
	
<h2>Selected Publications</h2>

(* denotes equal contributions)<br>
<strong>-2024-</strong>

<ul><li><p>How Abilities in Large Language Models are Affected by Supervised Fine-tuning Data Composition<br />
    <strong>Guanting Dong</strong>, Hongyi Yuan, Keming Lu, Chengpeng Li, Mingfeng Xue, Dayiheng Liu, Wei Wang, Zheng Yuan, Chang Zhou, Jingren Zhou<br />
    ACL 2024.
    <a href='https://arxiv.org/pdf/2310.05492.pdf'>[paper]</a>
	<a href='https://mp.weixin.qq.com/s/3RIBzuVlK0qHbO_Q04s-cw'>[blog]</a><br>
</li>
</ul>

<ul><li><p>Query and Response Augmentation Cannot Help Out-of-domain Math Reasoning Generalization<br />
Chengpeng Li, Zheng Yuan, Hongyi Yuan, <strong>Guanting Dong</strong>, Keming Lu, Jiancan Wu, Chuanqi Tan, Xiang Wang, Chang Zhou<br />
    ACL 2024. 
    <a href='https://arxiv.org/pdf/2310.05506.pdf'>[paper]</a>
	<a href='https://github.com/LHRLAB/ChatKBQA'>[code]</a>
	<a href='https://zhuanlan.zhihu.com/p/663463273'>[blog]</a><br>
</li>
</ul>
	
<ul><li><p>ChatKBQA: A Generate-then-Retrieve Framework for Knowledge Base Question Answering with Fine-tuned Large Language Models
<br />
Haoran Luo, Haihong E, Zichen Tang, Shiyao Peng, Yikai Guo, Wentai Zhang, Chenghao Ma, <strong>Guanting Dong</strong>, Meina Song, Wei Lin<br />
    Findings of ACL 2024. 
    <a href='https://arxiv.org/pdf/2310.08975'>[paper]</a>
	<a href='https://github.com/OFA-Sys/gsm8k-ScRel'>[code]</a>
	<a href='https://mp.weixin.qq.com/s/rBioXGaCefgOJnrkcSOs3A'>[blog]</a><br>
</li>
</ul>
	
<ul><li><p>DolphCoder: Echo-Locating Code Large Language Models with Diverse and Multi-Objective Instruction Tuning<br />
Yejie Wang, Keqing He, <strong>Guanting Dong</strong>, Pei Wang, Weihao Zeng, Muxi Diao, Yutao Mou, Mengdi Zhang, Jingang Wang, Xunliang Cai, Weiran Xu<br />
    ACL 2024.
    <a href='https://arxiv.org/pdf/2402.09136.pdf'>[paper]</a>
</li>
</ul>
	
<ul><li><p>Noise-BERT: A Unified Perturbation-Robust Framework with Noise Alignment Pre-training for Noisy Slot Filling Task<br />
Jinxu Zhao, <strong>Guanting Dong∗</strong>, Yueyan Qiu, Tingfeng Hui, Xiaoshuai Song, Daichi Guo, Weiran Xu<br />
ICASSP 2024. 
<a href='https://arxiv.org/pdf/2402.14494.pdf'>[paper]</a>
</li>
</ul>

	
<strong>-2023-</strong>

<ul><li><p>DemoNSF: A Multi-task Demonstration-based Generative Framework for Noisy Slot Filling Task<br />
<strong>Guanting Dong</strong>, Tingfeng Hui, Zhuoma GongQue, Jinxu Zhao, Daichi Guo, Gang Zhao, Keqing He, Weiran Xu<br />
Findings of EMNLP 2023. 
<a href='https://aclanthology.org/2023.findings-emnlp.705.pdf'>[paper]</a>
<a href='https://github.com/dongguanting/Demo-NSF'>[code]</a>
<a href='https://mp.weixin.qq.com/s/zkdUkybrTafPQR9wpVmi3w'>[blog]</a><br>
	
</li>
</ul>


<ul><li><p>Semantic Parsing by Large Language Models for Intricate Updating Strategies of Zero-Shot Dialogue State Tracking<br />
Yuxiang Wu, <strong>Guanting Dong*</strong>, Weiran Xu<br />
Findings of EMNLP 2023. 
<a href='https://aclanthology.org/2023.findings-emnlp.741.pdf'>[paper]</a>
<a href='https://github.com/ToLightUpTheSky/ParsingDST'>[code]</a> <br>
</li>
</ul>

<ul><li><p>A Multi-Task Semantic Decomposition Framework with Task-specific Pre-training for Few-Shot NER<br />
<strong>Guanting Dong</strong>, Zechen Wang, Jinxu Zhao, Gang Zhao, Daichi Guo, Dayuan Fu, Tingfeng Hui, Chen Zeng, Keqing He, Xuefeng Li, Liwen Wang, Xinyue Cui, Weiran Xu<br />
CIKM 2023 (Oral). 
<a href='https://arxiv.org/pdf/2308.14533.pdf'>[paper]</a>
<a href='https://github.com/dongguanting/MSDP-Fewshot-NER'>[code]</a> <br>
</li>
</ul>


<ul><li><p>Bridging the KB-Text Gap: Leveraging Structured Knowledge-aware Pre-training for KBQA<br />
<strong>Guanting Dong</strong>, Rumei Li, Sirui Wang, Yupeng Zhang, Yunsen Xian, Weiran Xu<br />
CIKM 2023. 
<a href='https://arxiv.org/pdf/2308.14436.pdf'>[paper]</a>
<a href='https://github.com/dongguanting/SKP-for-KBQA'>[code]</a> <br>
</li>
</ul>

<ul><li><p>Revisit Input Perturbation Problems for LLMs: A Unified Robustness Evaluation Framework for Noisy Slot Filling Task<br />
<strong>Guanting Dong</strong>,  Jinxu Zhao, Tingfeng Hui, Daichi Guo, Wenlong Wang, Boqi Feng, Yueyan Qiu, Zhuoma Gongque, Keqing He, Zechen Wang, Weiran Xu<br />
NLPCC 2023 (Oral). 
<a href='https://arxiv.org/pdf/2310.06504.pdf'>[paper]</a>
<a href='https://github.com/dongguanting/Noise-Slot-Filling-LLM'>[code]</a> <br>
</li>
</ul>


<ul><li><p>Generative Zero-Shot Prompt Learning for Cross-Domain Slot Filling with Inverse Prompting<br />
Xuefeng Li, Liwen Wang, <strong>Guanting Dong*</strong>, Keqing He, Jinzheng Zhao, Hao Lei, Jiachi Liu, Weiran Xu<br />
Findings of ACL 2023. 
<a href='https://aclanthology.org/2023.findings-acl.52.pdf'>[paper]</a>
<a href='https://github.com/LiXuefeng2020ai/GZPL'>[code]</a> <br>
</li>
</ul>


<ul><li><p>A Prototypical Semantic Decoupling Method via Joint Contrastive Learning for Few-Shot Named Entity Recognition<br />
<strong>Guanting Dong</strong>, Zechen Wang, Liwen Wang, Daichi Guo, Dayuan Fu, Yuxiang Wu, Chen Zeng, Xuefeng Li, Tingfeng Hui, Keqing He, Xinyue Cui, Qixiang Gao, Weiran Xu<br />
ICASSP 2023. 
<a href='https://ieeexplore.ieee.org/abstract/document/10095149'>[paper]</a>
</li>
</ul>

<ul><li><p>Revisit Out-Of-Vocabulary Problem For Slot Filling: A Unified Contrastive Framework With Multi-Level Data Augmentations<br />
Daichi Guo, <strong>Guanting Dong*</strong>, Dayuan Fu, Yuxiang Wu, Chen Zeng, Tingfeng Hui, Liwen Wang, Xuefeng Li, Zechen Wang, Keqing He, Xinyue Cui, Weiran Xu<br />
ICASSP 2023. 
<a href='https://ieeexplore.ieee.org/abstract/document/10094766/'>[paper]</a>
</li>
</ul>

<strong>-2022-</strong>

<ul><li><p>Exploiting domain-slot related keywords description for Few-Shot Cross-Domain Dialogue State Tracking<br />
Gao Qixiang, <strong>Guanting Dong*</strong>, Yutao Mou, Liwen Wang, Chen Zeng, Daichi Guo, Mingyang Sun, Weiran Xu<br />
EMNLP 2022 (Oral). 
<a href='https://aclanthology.org/2022.emnlp-main.157.pdf'>[paper]</a>
</li>
</ul>


<ul><li><p>Entity-level Interaction via Heterogeneous Graph for Multimodal Named Entity Recognition<br />
Gang Zhao, <strong>Guanting Dong</strong>, Yidong Shi, Haolong Yan, Weiran Xu, Si Li<br />
Findings of EMNLP 2022. 
<a href='https://aclanthology.org/2022.findings-emnlp.473.pdf'>[paper]</a>
<a href='https://github.com/GangZhao98/GEI'>[code]</a> <br>
</li>
</ul>


<ul><li><p>PSSAT: A Perturbed Semantic Structure Awareness Transferring Method for Perturbation-Robust Slot Filling<br />
<strong>Guanting Dong</strong>, Daichi Guo, Liwen Wang, Xuefeng Li, Zechen Wang, Chen Zeng, Keqing He, Jinzheng Zhao, Hao Lei, Xinyue Cui, Yi Huang, Junlan Feng, Weiran Xu<br />
COLING 2022. 
<a href='https://aclanthology.org/2022.coling-1.473.pdf'>[paper]</a>
</li>
</ul>






<h2>Honors & Awards</h2>
<ul>
    <!-- <li>
        <strong>China National Scholarship</strong>, 2023
    </li> -->
    <li>
        <strong>
            <a href="https://mp.weixin.qq.com/s/FhWj5PFPdgBfzp2QI8F28Q">National Scholarship for Master Students(Top 1%)</a>
        </strong>, 2023
    </li>

    <li>
        <strong>Outstanding Graduates of Beijing(Top 1%)</strong>, 2024
    </li>
	
    <li>
        <strong>Outstanding Graduate of Master Students(Top 5%), BUPT.</strong>, 2023
    </li>
    <li>
        <strong>Excellent First-class Scholarship for Master Students, BUPT. (Two times)</strong>, 2021, 2022
    </li>
    <li>
        <strong>
        <a href="http://seretod.org/Challenge.html">1st Award on track 2 of SereTOD Challenge, EMNLP 2022</a>
        </strong>, 2022
    </li>
    <li>
        <strong>Gold Award for College Music Festival Instrumental Performance, Beijing</strong>, 2021
    </li>
    <li>
        <strong>The Mathematical Contest in Modeling, Honorable Mention</strong>, 2021
    </li>

</ul>


<h2>Services</h2>
<strong>Reviewer for</strong>:
<ul>
    
    <li>
        <strong>ACL</strong> 2023
    </li>
    <li>
        <strong>EMNLP</strong> 2023
    </li>
    <li>
        <strong>NAACL</strong> 2023
    </li>
    <li>
        <strong>COLING</strong> 2023
    </li>
</ul>

<div id="footer">
	<div id="footer-text"></div>
</div>
&copy 2023 Guanting Dong  <br>

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
</script>  
总访问量<span id="busuanzi_value_site_pv"></span>次 <br>
总访客数<span id="busuanzi_value_site_uv"></span>人次 <br>

<a href="https://clustrmaps.com/site/1blbh"  title="Visit tracker for kunkuang.github.io"><img src="//www.clustrmaps.com/map_v2.png?d=Z8dyJa5Yjz2Z_i_LEAbfY0-TbrPurcZYl5i6ii_5Xbw&cl=ffffff" /></a>
</body>

</html>

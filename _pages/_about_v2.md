---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<span class='anchor' id='about-me'></span>
# About me
I am currently a 2nd year Ph.D. student at the [Gaoling School of Artificial Intelligence](https://ai.ruc.edu.cn/), [Renmin University of China](https://www.ruc.edu.cn/), fortunate to be co-advised by [Prof. Zhicheng Dou](http://playbigdata.ruc.edu.cn/dou/) and [Prof. Jirong Wen](https://scholar.google.com/citations?user=tbxCHJgAAAAJ&hl=zh-CN). I earned my M.Eng (2024) and B.Eng (2021) degrees in Information and Communication Engineering from [Beijing University of Posts and Telecommunications (BUPT)](https://www.bupt.edu.cn/), advised by [Prof. Weiran Xu](https://pris-nlp.github.io/en/author/weiran-xu/). 

I‚Äôm currently a Top Seed research intern focusing on general agent research at [Bytedance Seed](https://seed.bytedance.com/zh/). Previously, I held research intern roles with the the [Alibaba Qwen Team](https://github.com/QwenLM), [Kuaishou Klear Team](https://github.com/Kwai-Klear), and the Meituan NLP Center. I have published over **40+ papers in top-tier AI conferences and journals (10+ first author paper)**, including NeurIPS, ICLR, ACL, WWW, EMNLP, NAACL, AAAI, IP&M etc.

My long-term goal is to explore an **automated, scalable, and safe way that fosters exceptional intelligence to achieve AGI**.

**Research Interests:**
- Agentic Reinforcement Learning
- Deep Search Agent
- Alignment for Large Language Models


<span class='anchor' id='news'></span>
# üî• News
- *2025.10*: We introduce [AEPO](https://arxiv.org/pdf/2507.19849), designed to balance entropy for multi-turn LLM agent training! Featured as [ü§ó HF Daily Paper #2](https://huggingface.co/papers/2510.14545)ÔºÅ
- *2025.09*: üåê [WebThinker](https://arxiv.org/abs/2504.21776) is a powerful open-sourced deep research agent, which has been accepted by NeurIPS 2025!  Feel free to check out our [Demo](https://github.com/RUC-NLPIR/WebThinker)!
- *2024.08*: We introduce [ARPO](https://arxiv.org/pdf/2507.19849), an agentic RL algorithm for multi-turn LLM agents! Featured as [ü§ó HF Weekly Paper #1](https://huggingface.co/papers/2507.19849)ÔºÅ
- *2025.08*: üîç [Search-o1](https://arxiv.org/abs/2501.05366) has been accepted by EMNLP 2025 as Oral Presentation!
- *2025.05*: Four papers have been accepted by ACL 2025!
- *2025.05*: We propose üåü[Tool-Star](https://arxiv.org/abs/2505.16410), a LLM-brained multi-tool reasoner via RL! Check out our [project](https://github.com/dongguanting/Tool-Star)!
- *2025.02*: Our modular toolkit ‚ö°FlashRAG supports a range of [multimodal retrievers and generators](https://github.com/RUC-NLPIR/FlashRAG), please check it out!
- *2025.01*: [DPA-RAG](https://arxiv.org/pdf/2406.18676) has been accepted by WWW 2025, which is designed to align diverse preferences within RAG systems.
- *2025.01*: Two papers have been accepted by ICLR 2025! [AUTOIF](https://arxiv.org/pdf/2406.13542) is the secret behind <img src="/images/qwen_logo.webp" style="width: 1em;" /> Qwen's instruction-following alignment.
- *2024.12*: Honored to be a contributor to the Qwen2.5 <img src="/images/qwen_logo.webp" style="width: 1em;" />, a series of LLMs designed to meet diverse needs!
- *2024.09*: Glad to be a Ph.D. student at GSAI, Renmin University of China.
- *2024.09*: Two papers have been accepted by EMNLP 2024!
- *2024.07*: We release our technical report of Qwen2 <img src="/images/qwen_logo.webp" style="width: 1em;" />. a large-scale language model developed by Alibaba Group.
- *2024.05*: Four papers have been accepted by ACL 2024! Looking forward to seeing you in Bangkok!


<span class='anchor' id='education'></span>
# üìñ Education
- 2024.9 - Now, <img src="/images/ruc.webp" style="width: 1em;"> Ph.D, Gaoling School of Artificial Intelligence, Renmin University of China.
- 2021.9 - 2024.6, <img src="/images/bupt.webp" style="width: 1em;"> M.Eng, Artificial Intelligence, Beijing University of Posts and Telecommunications.
- 2017.9 - 2021.6, <img src="/images/bupt.webp" style="width: 1em;"> B.Eng, Information and Communication Engineering, Beijing University of Posts and Telecommunications.
- 2018.7 - 2018.8, <img src="/images/oxford.webp" style="width: 1em;"> Summer Exchange Internship, University of Oxford.


<span class='anchor' id='experiences'></span>
# üíª Experiences

- 2025.11 - Present, <img src="/images/bytedance.png" style="width: 3.3em;">ByteDance, Seed General Agent Team
  - Research Intern on RL for General Agent <span style="color: red;">(Top Seed Program)</span>, Mentor: [Wanjun Zhong](https://scholar.google.com/citations?user=FGIZfyQAAAAJ&hl=zh-CN)

- 2025.4 - 2025.11, <img src="/images/kuaishou_v2.png" style="width: 2.8em;"> Kuaishou, Foundation LLM Team
  - Research Intern on Agentic RL & Deep Search Agent <span style="color: red;">(K-Star Program)</span>, Mentor: [Hangyu Mao](https://scholar.google.com/citations?user=EtVHsgcAAAAJ&hl=zh-CN&oi=ao), [Fuzheng Zhang](https://scholar.google.com/citations?user=8R0hla4AAAAJ&hl=zh-CN)


- 2023.6 - 2024.8, <img src="/images/alibaba.png" style="width: 2.4em;"> Alibaba, <img src="/images/qwen_logo.webp" style="width: 1em;" /> Qwen Foundation LLM Team 
  - Research Intern on Alignment & Reasoning of Large Language Models, Mentor: [Bowen Yu](https://scholar.google.com/citations?user=oHoEp34AAAAJ&hl=zh-CN), [Zheng Yuan](https://scholar.google.com/citations?user=kRgiVnUAAAAJ&hl=zh-CN), [Wei Wang](https://scholar.google.com/citations?user=0zSeT3oAAAAJ&hl=zh-CN), [Keming Lu](https://scholar.google.com/citations?user=T7_gdokAAAAJ&hl=zh-CN)


- 2022.9 - 2023.5, <img src="/images/meituan.png" style="width: 2.4em;"> Meituan, NLP Center
  - Research Intern on Knowledge Augmented Generation, Mentor: [Rumei Li](https://scholar.google.com/citations?user=zlWAv4gAAAAJ&hl=zh-CN&oi=ao)



<span class='anchor' id='honors-awards'></span>
# üèÜ Selected Honors & Awards & Grants 

- Fundamental Research Project for PhD Students, National Natural Science Foundation of ChinaÔºà**ÂõΩÂÆ∂Ëá™ÁÑ∂ÁßëÂ≠¶Âü∫ÈáëÈùíÂπ¥Â≠¶ÁîüÂü∫Á°ÄÁ†îÁ©∂È°πÁõÆ(ÂçöÂ£´Áîü)**Ôºâ, 2026.01-2027.12
- **National Scholarship for Ph.D Students(ÂçöÂ£´ÁîüÂõΩÂÆ∂Â•ñÂ≠¶ÈáëÔºåTop 1%)**, 2025
- **[1st Place in the PhD Entrance Exam (Preliminary) at the GSAI, Renmin University of China](http://ai.ruc.edu.cn/newslist/notice/20240301100.html)**, 2024
- **[Outstanding Graduates of Beijing(Âåó‰∫¨Â∏Ç‰ºòÁßÄÊØï‰∏öÁîüÔºåTop 1%)](https://jw.beijing.gov.cn/tzgg/202410/t20241010_3916096.html)**, 2024
- **[National Scholarship for Master Students (Á°ïÂ£´ÁîüÂõΩÂÆ∂Â•ñÂ≠¶ÈáëÔºåTop 1%)](https://mp.weixin.qq.com/s/FhWj5PFPdgBfzp2QI8F28Q)**, 2023
- **Excellent First-class Scholarship for Master Students, BUPT(Two times)**, 2021, 2022
- **[1st Award on track 2 of SereTOD Challenge, EMNLP 2022](http://seretod.org/Challenge.html)**, 2022
- **The American Mathematical Contest in Modeling, Honorable Mention**, 2021


<span class='anchor' id='honors-awards'></span>
# üèÜ Invited Talks 

- *2025.11*: [Êô∫ËÉΩ‰ΩìÂº∫ÂåñÁ≠ñÁï•‰ºòÂåñ](https://mp.weixin.qq.com/s/0nwK7_dodh5vUZSRKHt57Q), MLNLP Community
- *2025.10*: [EAXËÆ≤Â∫ß-Êô∫ËÉΩ‰ΩìÂº∫ÂåñÁ≠ñÁï•‰ºòÂåñ](https://www.xiaohongshu.com/explore/68ff6b72000000000303575f?xsec_token=ABJFcX0C9H8bFb8eKJfiGs6tpalgZD66vItoOTJYG0-KI=&xsec_source=pc_search&source=unknown), EvoAgentX Community
- *2025.09*: Êô∫ËÉΩ‰ΩìÂº∫ÂåñÁ≠ñÁï•‰ºòÂåñ, HunYuan Team, Tencent
- *2025.08*: [ARPO: ËÆ©‰Ω†ÁöÑAgentÂú®ÂÖ≥ÈîÆÊó∂Âàª‚ÄúÂ§öÊé¢Á¥¢‰∏ÄÊ≠•‚Äù!](https://mp.weixin.qq.com/s/mwH3FsNHgsFyGqsX-VMPCQ), NICE Community


# üìù Selected Preprint
\* for corresponding author, <sup>\#</sup> for equal contribution.

- [**Qwen2.5 Technical Report**](https://arxiv.org/pdf/2412.15115) <img src="/images/qwen_logo.webp" style="width: 1em;">\
<span style="font-size: 0.869em;"><img src="./images/logo-author.png" style="width: 1em; position: relative; top: -0.1em;"> Qwen Team (129 authors including **Guanting Dong**).</span>\
<a href="https://github.com/QwenLM/Qwen2.5"><img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/QwenLM/Qwen2.5?style=flat-square&logo=github&logoColor=black&labelColor=white&color=white&label=Stars&cacheSeconds=10" style="border: 1px solid #ccc; border-radius: 4px;"></a> <a href='https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3510016946558774011,11619912401772234101,11615265854926769370,14079262223945488637,6779142923552910780,16263764723370237,16732198439819746935,11230843588830844781,15058282688966402390,5393577902069513696,12340246327603914630,11107726774567213966,9157790648878278523,16210109515189124329,10233194812256490256,8869895852053621447,7081446660002974513,1893666384802217392,10881426119513058258,8800937914660717198,965333516966951963,8114150780830323247,7426744583932315627,5174914509262780326'><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fraw.githubusercontent.com%2Fdongguanting%2Fdongguanting.github.io%2Fgoogle-scholar-stats%2Fgs_data.json&query=%24.publications.%5B%27amozZDkAAAAJ%3AZuybSZzF8UAC%27%5D.num_citations&label=Citations&color=white&logo=Google%20Scholar&style=flat-square&labelColor=white" style="border: 1px solid #ccc; border-radius: 4px;"></a>

- [**Qwen2 Technical Report**](https://arxiv.org/pdf/2407.10671) <img src="/images/qwen_logo.webp" style="width: 1em;">\
<span style="font-size: 0.869em;"><img src="./images/logo-author.png" style="width: 1em; position: relative; top: -0.1em;"> Qwen Team (64 authors including **Guanting Dong**).</span>\
<a href="https://github.com/QwenLM/Qwen2"><img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/QwenLM/Qwen2?style=flat-square&logo=github&logoColor=black&labelColor=white&color=white&label=Stars&cacheSeconds=10" style="border: 1px solid #ccc; border-radius: 4px;"></a> <a href='https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6672924329882884012,13971550000182823781,9434020372561789113,4456283276021881948,5325387458673779549,16295649840601144699,3052072785526961060,8649603210022484583,12405196294611647953,11577184677612024258,14134743843581242989,13499414721523435330,10508627037847251469,15330312081372582673,9417609393760912068,4517254539532060540,16053125865865457928,4766810347142664970,16592704758270555254,88435932941922515'><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fraw.githubusercontent.com%2Fdongguanting%2Fdongguanting.github.io%2Fgoogle-scholar-stats%2Fgs_data.json&query=%24.publications.%5B%27amozZDkAAAAJ%3ANMxIlDl6LWMC%27%5D.num_citations&label=Citations&color=white&logo=Google%20Scholar&style=flat-square&labelColor=white" style="border: 1px solid #ccc; border-radius: 4px;"></a>

- [**Scaling relationship on learning mathematical reasoning with large language models**](https://arxiv.org/pdf/2308.01825.pdf) <img src="/images/qwen_logo.webp" style="width: 1em;">\
<span style="font-size: 0.869em;"><img src="./images/logo-author.png" style="width: 1em; position: relative; top: -0.1em;"> Zheng Yuan, Hongyi Yuan, Chengpeng Li, **Guanting Dong**, Chuanqi Tan, Chang Zhou.</span>\
<a href="https://github.com/OFA-Sys/gsm8k-ScRel"><img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/OFA-Sys/gsm8k-ScRel?style=flat-square&logo=github&logoColor=black&labelColor=white&color=white&label=Stars&cacheSeconds=10" style="border: 1px solid #ccc; border-radius: 4px;"></a> <a href='https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12498281829120693895,13367506569625532766,922644339147896019,12305037050315294054,1828524421597419848'><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fraw.githubusercontent.com%2Fdongguanting%2Fdongguanting.github.io%2Fgoogle-scholar-stats%2Fgs_data.json&query=%24.publications.%5B%27amozZDkAAAAJ%3AhkOj_22Ku90C%27%5D.num_citations&label=Citations&color=white&logo=Google%20Scholar&style=flat-square&labelColor=white" style="border: 1px solid #ccc; border-radius: 4px;"></a>

- [**InstructERC: Reforming Emotion Recognition in Conversation with a Retrieval Multi-task LLMs Framework**](https://arxiv.org/pdf/2309.11911.pdf)\
<span style="font-size: 0.869em;"><img src="./images/logo-author.png" style="width: 1em; position: relative; top: -0.1em;"> Shanglin Lei, **Guanting Dong**<sup>*</sup>, Xiaoping Wang, Keheng Wang, Sirui Wang.</span>\
<a href="https://github.com/LIN-SHANG/InstructERC"><img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/LIN-SHANG/InstructERC?style=flat-square&logo=github&logoColor=black&labelColor=white&color=white&label=Stars&cacheSeconds=10" style="border: 1px solid #ccc; border-radius: 4px;"></a> <a href='https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3337108481848758803,14584019459839657100,13455366788808433850,17768959771348568265'><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fraw.githubusercontent.com%2Fdongguanting%2Fdongguanting.github.io%2Fgoogle-scholar-stats%2Fgs_data.json&query=%24.publications.%5B%27amozZDkAAAAJ%3AufrVoPGSRksC%27%5D.num_citations&label=Citations&color=white&logo=Google%20Scholar&style=flat-square&labelColor=white" style="border: 1px solid #ccc; border-radius: 4px;"></a>

- [**Agentic Entropy-Balanced Policy Optimization**](https://arxiv.org/abs/2510.14545)\
<span style="font-size: 0.869em;"><img src="./images/logo-author.png" style="width: 1em; position: relative; top: -0.1em;"> **Guanting Dong**, Licheng Bao, Zhongyuan Wang, Kangzhi Zhao, Xiaoxi Li, Jiajie Jin, Jinghan Yang, Hangyu Mao, Fuzheng Zhang, Kun Gai, Guorui Zhou, Yutao Zhu, Ji-Rong Wen, Zhicheng Dou.</span>\
<a href="https://github.com/dongguanting/ARPO"><img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/dongguanting/ARPO?style=flat-square&logo=github&logoColor=black&labelColor=white&color=white&label=Stars&cacheSeconds=10" style="border: 1px solid #ccc; border-radius: 4px;"></a>

- [**Agentic Reinforced Policy Optimization**](https://arxiv.org/pdf/2507.19849)\
<span style="font-size: 0.869em;"><img src="./images/logo-author.png" style="width: 1em; position: relative; top: -0.1em;"> **Guanting Dong**, Hangyu Mao, Kai Ma, Licheng Bao, Yifei Chen, Zhongyuan Wang, Zhongxia Chen, Jiazhen Du, Huiyang Wang, Fuzheng Zhang, Guorui Zhou, Yutao Zhu, Ji-Rong Wen, Zhicheng Dou.</span>\
<a href="https://github.com/dongguanting/ARPO"><img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/dongguanting/ARPO?style=flat-square&logo=github&logoColor=black&labelColor=white&color=white&label=Stars&cacheSeconds=10" style="border: 1px solid #ccc; border-radius: 4px;"></a> <a href='https://scholar.google.com/scholar?cites=6207851523271813385&as_sdt=2005&sciodt=0,5&hl=zh-CN'><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fraw.githubusercontent.com%2Fdongguanting%2Fdongguanting.github.io%2Fgoogle-scholar-stats%2Fgs_data.json&query=%24.publications.%5B%27amozZDkAAAAJ%3AJQOojiI6XY0C%27%5D.num_citations&label=Citations&color=white&logo=Google%20Scholar&style=flat-square&labelColor=white" style="border: 1px solid #ccc; border-radius: 4px;"></a>

- [**Tool-Star: Empowering LLM-Brained Multi-Tool Reasoner via Reinforcement Learning**](https://arxiv.org/abs/2505.16410)\
<span style="font-size: 0.869em;"><img src="./images/logo-author.png" style="width: 1em; position: relative; top: -0.1em;"> **Guanting Dong**, Yifei Chen, Xiaoxi Li, Jiajie Jin, Hongjin Qian, Yutao Zhu, Hangyu Mao, Guorui Zhou, Zhicheng Dou, Ji-Rong Wen.</span>\
<a href="https://github.com/dongguanting/Tool-Star"><img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/dongguanting/Tool-Star?style=flat-square&logo=github&logoColor=black&labelColor=white&color=white&label=Stars&cacheSeconds=10" style="border: 1px solid #ccc; border-radius: 4px;"></a>


# üìù Selected Publications ([Full Publications](https://scholar.google.com/citations?user=amozZDkAAAAJ&hl=zh-CN))

- [**WebThinker: Empowering Large Reasoning Models with Deep Research Capability**](https://arxiv.org/abs/2504.21776)\
<span style="font-size: 0.869em;"><img src="./images/logo-author.png" style="width: 1em; position: relative; top: -0.1em;"> Xiaoxi Li, Jiajie Jin, **Guanting Dong**, Hongjin Qian, Yongkang Wu, Ji-Rong Wen, Yutao Zhu, and Zhicheng Dou.</span>\
<span style="font-size: 0.87em; color: #c00000;"><img src="./images/logo-venue.png" style="width: 0.975em; position: relative; top: -0.115em; margin-left: 0.005em;"> **NeurIPS 2025 (CCF-A)**</span>\
<a href="https://github.com/RUC-NLPIR/WebThinker"><img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/RUC-NLPIR/WebThinker?style=flat-square&logo=github&logoColor=black&labelColor=white&color=white&label=Stars&cacheSeconds=10" style="border: 1px solid #ccc; border-radius: 4px;"></a> <a href='https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2494358555732420670'><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fraw.githubusercontent.com%2Fdongguanting%2Fdongguanting.github.io%2Fgoogle-scholar-stats%2Fgs_data.json&query=%24.publications.%5B%27amozZDkAAAAJ%3Ap2g8aNsByqUC%27%5D.num_citations&label=Citations&color=white&logo=Google%20Scholar&style=flat-square&labelColor=white" style="border: 1px solid #ccc; border-radius: 4px;"></a>

- [**Search-o1: Agentic Search-Enhanced Large Reasoning Models**](https://arxiv.org/abs/2501.05366)\
<span style="font-size: 0.869em;"><img src="./images/logo-author.png" style="width: 1em; position: relative; top: -0.1em;"> Xiaoxi Li, **Guanting Dong**, Jiajie Jin, Yuyao Zhang, Yujia Zhou, Yutao Zhu, Peitian Zhang, and Zhicheng Dou.</span>\
<span style="font-size: 0.87em; color: #c00000;"><img src="./images/logo-venue.png" style="width: 0.975em; position: relative; top: -0.115em; margin-left: 0.005em;"> **EMNLP 2025 (CCF-B)**</span>\
<a href="https://github.com/sunnynexus/Search-o1"><img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/sunnynexus/Search-o1?style=flat-square&logo=github&logoColor=black&labelColor=white&color=white&label=Stars&cacheSeconds=10" style="border: 1px solid #ccc; border-radius: 4px;"></a> <a href='https://scholar.google.com/scholar?oi=bibs&hl=en&cites=283590861766656057,17334087535406948909,11110584847133377481'><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fraw.githubusercontent.com%2Fdongguanting%2Fdongguanting.github.io%2Fgoogle-scholar-stats%2Fgs_data.json&query=%24.publications.%5B%27amozZDkAAAAJ%3AM05iB0D1s5AC%27%5D.num_citations&label=Citations&color=white&logo=Google%20Scholar&style=flat-square&labelColor=white" style="border: 1px solid #ccc; border-radius: 4px;"></a>

- [**RAG-Critic: Leveraging Automated Critic-Guided Agentic Workflow for Retrieval Augmented Generation**](https://arxiv.org/pdf/2412.14835)\
<span style="font-size: 0.869em;"><img src="./images/logo-author.png" style="width: 1em; position: relative; top: -0.1em;"> **Guanting Dong**, Chenghao Zhang, Mengjie Deng, Yutao Zhu, Zhicheng Dou, and Ji-Rong Wen.</span>\
<span style="font-size: 0.87em; color: #c00000;"><img src="./images/logo-venue.png" style="width: 0.975em; position: relative; top: -0.115em; margin-left: 0.005em;"> **ACL 2025 (CCF-A)**</span>\
<a href="https://github.com/dongguanting/RAG-Critic"><img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/dongguanting/RAG-Critic?style=flat-square&logo=github&logoColor=black&labelColor=white&color=white&label=Stars&cacheSeconds=10" style="border: 1px solid #ccc; border-radius: 4px;"></a>

- [**Progressive Multimodal Reasoning via Active Retrieval**](https://arxiv.org/pdf/2412.14835)\
<span style="font-size: 0.869em;"><img src="./images/logo-author.png" style="width: 1em; position: relative; top: -0.1em;"> **Guanting Dong**, Chenghao Zhang, Mengjie Deng, Yutao Zhu, Zhicheng Dou, and Ji-Rong Wen.</span>\
<span style="font-size: 0.87em; color: #c00000;"><img src="./images/logo-venue.png" style="width: 0.975em; position: relative; top: -0.115em; margin-left: 0.005em;"> **ACL 2025 (CCF-A)**</span>

- [**We-Math: Does Your Large Multimodal Model Achieve Human-like Mathematical Reasoning?**](https://arxiv.org/pdf/2407.01284)\
<span style="font-size: 0.869em;"><img src="./images/logo-author.png" style="width: 1em; position: relative; top: -0.1em;"> Runqi Qiao, Qiuna Tan, **Guanting Dong**<sup>\#</sup>, Minhui Wu, Chong Sun, Xiaoshuai Song, Zhuoma GongQue, Shanglin Lei, Zhe Wei, Miaoxuan Zhang, Runfeng Qiao, Yifan Zhang, Xiao Zong, Yida Xu, Muxi Diao, Zhimin Bao, Chen Li, Honggang Zhang.</span>\
<span style="font-size: 0.87em; color: #c00000;"><img src="./images/logo-venue.png" style="width: 0.975em; position: relative; top: -0.115em; margin-left: 0.005em;"> **ACL 2025 (CCF-A)**</span>\
<a href="https://github.com/We-Math/We-Math"><img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/We-Math/We-Math?style=flat-square&logo=github&logoColor=black&labelColor=white&color=white&label=Stars&cacheSeconds=10" style="border: 1px solid #ccc; border-radius: 4px;"></a> <a href='https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=9870861752242716648&as_sdt=5'><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fraw.githubusercontent.com%2Fdongguanting%2Fdongguanting.github.io%2Fgoogle-scholar-stats%2Fgs_data.json&query=%24.publications.%5B%27amozZDkAAAAJ%3A4fKUyHm3Qg0C%27%5D.num_citations&label=Citations&color=white&logo=Google%20Scholar&style=flat-square&labelColor=white" style="border: 1px solid #ccc; border-radius: 4px;"></a>

- [**Understand What LLM Needs: Dual Preference Alignment for Retrieval-Augmented Generation**](https://arxiv.org/pdf/2406.18676)\
<span style="font-size: 0.869em;"><img src="./images/logo-author.png" style="width: 1em; position: relative; top: -0.1em;"> **Guanting Dong**, Yutao Zhu, Chenghao Zhang, Zechen Wang, Zhicheng Dou, and Ji-Rong Wen.</span>\
<span style="font-size: 0.87em; color: #c00000;"><img src="./images/logo-venue.png" style="width: 0.975em; position: relative; top: -0.115em; margin-left: 0.005em;"> **WWW 2025 (CCF-A)**</span>\
<a href="https://github.com/dongguanting/DPA-RAG"><img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/dongguanting/DPA-RAG?style=flat-square&logo=github&logoColor=black&labelColor=white&color=white&label=Stars&cacheSeconds=10" style="border: 1px solid #ccc; border-radius: 4px;"></a> <a href='https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4738668290193574246,13381452394503616725'><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fraw.githubusercontent.com%2Fdongguanting%2Fdongguanting.github.io%2Fgoogle-scholar-stats%2Fgs_data.json&query=%24.publications.%5B%27amozZDkAAAAJ%3A7PzlFSSx8tAC%27%5D.num_citations&label=Citations&color=white&logo=Google%20Scholar&style=flat-square&labelColor=white" style="border: 1px solid #ccc; border-radius: 4px;"></a>

- [**Toward General Instruction-Following Alignment for Retrieval-Augmented Generation**](https://arxiv.org/abs/2410.09584)\
<span style="font-size: 0.869em;"><img src="./images/logo-author.png" style="width: 1em; position: relative; top: -0.1em;"> **Guanting Dong**, Xiaoshuai Song, Yutao Zhu, Runqi Qiao, Zhicheng Dou, and Ji-Rong Wen.</span>\
<span style="font-size: 0.87em; color: #c00000;"><img src="./images/logo-venue.png" style="width: 0.975em; position: relative; top: -0.115em; margin-left: 0.005em;"> **AAAI 2025 (CCF-A)**</span>\
<a href="https://github.com/dongguanting/FollowRAG"><img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/dongguanting/FollowRAG?style=flat-square&logo=github&logoColor=black&labelColor=white&color=white&label=Stars&cacheSeconds=10" style="border: 1px solid #ccc; border-radius: 4px;"></a>

- [**Self-play with Execution Feedback: Improving Instruction-following Capabilities of Large Language Models**](https://arxiv.org/pdf/2406.13542)\
<span style="font-size: 0.869em;"><img src="./images/logo-author.png" style="width: 1em; position: relative; top: -0.1em;"> **Guanting Dong**, Keming Lu, Chengpeng Li, Tingyu Xia, Bowen Yu, Chang Zhou, Jingren Zhou.</span>\
<span style="font-size: 0.87em; color: #c00000;"><img src="./images/logo-venue.png" style="width: 0.975em; position: relative; top: -0.115em; margin-left: 0.005em;"> **ICLR 2025 Spotlight (CCF-A)**</span>\
<a href="https://github.com/QwenLM/AutoIF"><img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/QwenLM/AutoIF?style=flat-square&logo=github&logoColor=black&labelColor=white&color=white&label=Stars&cacheSeconds=10" style="border: 1px solid #ccc; border-radius: 4px;"></a> <a href='https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16109051854272212147'><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fraw.githubusercontent.com%2Fdongguanting%2Fdongguanting.github.io%2Fgoogle-scholar-stats%2Fgs_data.json&query=%24.publications.%5B%27amozZDkAAAAJ%3AdhFuZR0502QC%27%5D.num_citations&label=Citations&color=white&logo=Google%20Scholar&style=flat-square&labelColor=white" style="border: 1px solid #ccc; border-radius: 4px;"></a>

- [**CS-Bench: A Comprehensive Benchmark for Large Language Models towards Computer Science Mastery**](https://arxiv.org/pdf/2406.08587)\
<span style="font-size: 0.869em;"><img src="./images/logo-author.png" style="width: 1em; position: relative; top: -0.1em;"> Xiaoshuai Song, Muxi Diao, **Guanting Dong**, Zhengyang Wang, Yujia Fu, Runqi Qiao, Zhexu Wang, Dayuan Fu, Huangxuan Wu, Bin Liang, Weihao Zeng, Yejie Wang, Zhuoma GongQue, Jianing Yu, Qiuna Tan, Weiran Xu.</span>\
<span style="font-size: 0.87em; color: #c00000;"><img src="./images/logo-venue.png" style="width: 0.975em; position: relative; top: -0.115em; margin-left: 0.005em;"> **ICLR 2025 (CCF-A)**</span>\
<a href="https://github.com/csbench/csbench"><img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/csbench/csbench?style=flat-square&logo=github&logoColor=black&labelColor=white&color=white&label=Stars&cacheSeconds=10" style="border: 1px solid #ccc; border-radius: 4px;"></a>

- [**FlashRAG: A Python Toolkit for Efficient RAG Research**](https://arxiv.org/pdf/2405.13576) ‚ö°\
<span style="font-size: 0.869em;"><img src="./images/logo-author.png" style="width: 1em; position: relative; top: -0.1em;"> Jiajie Jin, Yutao Zhu, **Guanting Dong**, Yuyao Zhang, Xinyu Yang, Chenghao Zhang, Tong Zhao, Zhao Yang, Zhicheng Dou, Ji-Rong Wen.</span>\
<span style="font-size: 0.87em; color: #c00000;"><img src="./images/logo-venue.png" style="width: 0.975em; position: relative; top: -0.115em; margin-left: 0.005em;"> **WWW 2025 (CCF-A)**</span>\
<a href="https://github.com/RUC-NLPIR/FlashRAG"><img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/RUC-NLPIR/FlashRAG?style=flat-square&logo=github&logoColor=black&labelColor=white&color=white&label=Stars&cacheSeconds=10" style="border: 1px solid #ccc; border-radius: 4px;"></a> <a href='https://scholar.google.com/scholar?cites=9469234542264958612&as_sdt=2005&sciodt=0,5&hl=zh-CN'><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fraw.githubusercontent.com%2Fdongguanting%2Fdongguanting.github.io%2Fgoogle-scholar-stats%2Fgs_data.json&query=%24.publications.%5B%27amozZDkAAAAJ%3A738O_yMBCRsC%27%5D.num_citations&label=Citations&color=white&logo=Google%20Scholar&style=flat-square&labelColor=white" style="border: 1px solid #ccc; border-radius: 4px;"></a>

- [**How Abilities in Large Language Models are Affected by Supervised Fine-tuning Data Composition**](https://arxiv.org/pdf/2310.05492.pdf)\
<span style="font-size: 0.869em;"><img src="./images/logo-author.png" style="width: 1em; position: relative; top: -


<span class='anchor' id='academic-services'></span>
# üîç Academic Services

- **Invited Reviewer for Journals**:
  - Knowledge-Based Systems (KBS)

- **SPC Reviewer for**: 
  - AAAI: 2026

- **Program Committee Member / Reviewer for Conferences**:
  - NeurIPS: 2024‚Äì2025
  - ICML: 2025
  - ICLR: 2023-2026
  - KDD: 2025
  - SIGIR: 2025
  - WWW: 2025-2026
  - ACL ARR: 2024-2026
  - AAAI: 2026
  - CIKM: 2024‚Äì2025


<hr style="margin-top: 3em;">

<div id="footer" style="text-align: center; font-size: 0.9em; color: #666;">
  <div id="footer-text"></div>

  &copy; 2025 Guanting Dong<br><br>

  ÊÄªËÆøÈóÆÈáè <span id="busuanzi_value_site_pv"></span> Ê¨°<br>
  ÊÄªËÆøÂÆ¢Êï∞ <span id="busuanzi_value_site_uv"></span> ‰∫∫Ê¨°<br><br>

  <a href="https://clustrmaps.com/site/1blbh" title="Visit tracker">
    <img 
      src="//www.clustrmaps.com/map_v2.png?d=Z8dyJa5Yjz2Z_i_LEAbfY0-TbrPurcZYl5i6ii_5Xbw&cl=ffffff"
      alt="Visitor Map"
      style="width: 300px;"
    />
  </a>
</div>

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
